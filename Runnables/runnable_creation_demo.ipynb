{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449df596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699fd54",
   "metadata": {},
   "source": [
    "Creating LLM Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLLM:\n",
    "#Methods creation within class\n",
    "    def __init__(self): #constrcutor method : default calling of class\n",
    "        print(\"Dummy LLM Created\")\n",
    "    \n",
    "    def predict(self, prompt):\n",
    "\n",
    "        response_list  = [\n",
    "            \"Lucknow is capital of India\",\n",
    "            \"Euro is european football championship\",\n",
    "            \"LLM stands for large langauge models\"\n",
    "        ]\n",
    "        return {'response':random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c84e3ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy LLM Created\n"
     ]
    }
   ],
   "source": [
    "llm = dummyLLM() # calling using constructor method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05d8560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Lucknow is capital of India'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Who is ram?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31088f",
   "metadata": {},
   "source": [
    "Creating Template Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90e5c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLLMtemplate:\n",
    "\n",
    "    def __init__(self,template, input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "    def format(self, input_dict):\n",
    "        return self.template.format(**input_dict)\n",
    "\n",
    "#** is dictionary unpacking\n",
    "\n",
    "# It passes keyâ€“value pairs as named arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7aa0efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving values to  dummyLLMtemplate\n",
    "template = dummyLLMtemplate(\n",
    "    template= \"Write a {length} story about {topic}\",\n",
    "    input_variables= [\"length\",\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35eda2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.dummyLLMtemplate at 0x79bb57c5e0f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e152b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format({\"length\":\"short\",'topic':'india'}) #unpacking dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afcd5705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Write a short story about india'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec1d5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy LLM Created\n"
     ]
    }
   ],
   "source": [
    "llm = dummyLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b0c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'LLM stands for large langauge models'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732bd170",
   "metadata": {},
   "source": [
    "Creating LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb38131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMchain:\n",
    "    def __init__(self,llm, prompt):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def run(self,input_dict):\n",
    "\n",
    "        final_prompt = self.prompt.format(input_dict)\n",
    "        result = self.llm.predict(final_prompt)\n",
    "\n",
    "        return result['response']\n",
    "    \n",
    "    # These chains are not flexible because it is hard to call this llm (run) more than one time like chain = prompt | llm | llm_output | llm\n",
    "    # Because llm and prompt have diferent methods for calling or intercating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4640a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMchain(llm,template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb4a5a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Lucknow is capital of India'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"length\":\"short\",'topic':'india'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd2567",
   "metadata": {},
   "source": [
    "Standardized Components (LLM and Prompt) using runnables by having common methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b803a",
   "metadata": {},
   "source": [
    "Using abstraction (OOP) (abstract class Runnable) : we will create all components which will inhertiate properties from runnable\n",
    "and, so we will automatically to have implement same methods of Runnable class\n",
    "in all of the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8621078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c8dade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable(ABC):\n",
    "    @abstractmethod  # it just abstract (no code for execution here)\n",
    "    def invoke(input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fce46f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLLM(Runnable):\n",
    "#Methods creation within class\n",
    "    def __init__(self): #constrcutor method : deafult calling of class\n",
    "        print(\"Dummy LLM Created\")\n",
    "    \n",
    "    def predict(self, prompt):\n",
    "\n",
    "        response_list  = [\n",
    "            \"Lucknow is capital of India\",\n",
    "            \"Euro is european football championship\",\n",
    "            \"LLM stands for large langauge models\"\n",
    "        ]\n",
    "        return {'response':random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9553de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = dummyLLM()\n",
    "# TypeError: Can't instantiate abstract class dummyLLM without an implementation for abstract method 'invoke'\n",
    "# You have to use invoke method here : way of making sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98475a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLLM(Runnable):\n",
    "#Methods creation within class\n",
    "    def __init__(self): #constrcutor method : deafult calling of class\n",
    "        print(\"Dummy LLM Created\")\n",
    "    \n",
    "     \n",
    "    def predict(self, prompt):\n",
    "\n",
    "        response_list  = [\n",
    "            \"Lucknow is capital of India\",\n",
    "            \"Euro is european football championship\",\n",
    "            \"LLM stands for large langauge models\"\n",
    "        ]\n",
    "        return {'response':random.choice(response_list),\"message\" : \"This method is going to be deprecated\"}\n",
    "    \n",
    "    def invoke(self, prompt):\n",
    "\n",
    "        response_list  = [\n",
    "            \"Lucknow is capital of India\",\n",
    "            \"Euro is european football championship\",\n",
    "            \"LLM stands for large langauge models\"\n",
    "        ]\n",
    "        return {'response':random.choice(response_list)}\n",
    "# We should not remove predict method because some people will be still using it\n",
    "# need to give warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e37723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLLMtemplate(Runnable):\n",
    "\n",
    "    def __init__(self,template, input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "    def format(self, input_dict):\n",
    "        return self.template.format(**input_dict + \"This method is going to be deprecated\")\n",
    "    \n",
    "    def invoke(self, input_dict):\n",
    "        return self.template.format(**input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db3cdc",
   "metadata": {},
   "source": [
    "Forming chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9843641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnableConnector(Runnable):\n",
    "    def __init__(self,runnable_list):\n",
    "        self.runnable_list = runnable_list\n",
    "\n",
    "    def invoke(self,input_data):\n",
    "        for runnable in self.runnable_list:\n",
    "            input_data = runnable.invoke(input_data)\n",
    "        return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84ba2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = dummyLLMtemplate(\n",
    "    template='Write a {length} poem about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5d65b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy LLM Created\n"
     ]
    }
   ],
   "source": [
    "llm = dummyLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee003dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableConnector([template,llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84226f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Lucknow is capital of India'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"length\":\"short\",'topic':'india'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db7efe",
   "metadata": {},
   "source": [
    "Now, we can connect many components like parser, loader in as child of runnable abstract class and can connect easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79d0824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class parser(Runnable):\n",
    "\n",
    "    def __init__(self):\n",
    "      pass\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "      return input_data['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7129bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c84d301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableConnector([template,llm,parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6fa1aefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'LLM stands for large langauge models'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"length\":\"short\",'topic':'india'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
